# health_news_LDA_topics
Investigating LDA on short, specific health news text data and subsets of women's, men's and children's health to see differences in salience and frequency of terms across subsets.

The goal of this project was to 1) use LDA on shorter data like tweets within a specific domain, and 2) identify differences in predominant topics and their salience with smaller subsets of women's health news, men's health news, and health news related to children. The health news tweets were obtained from the [UCI ML Repository](https://archive.ics.uci.edu/dataset/438/health+news+in+twitter), and contain tweets from several different news sources. This analysis uses the cleaned Reuters dataset due to its size and global news coverage.

The full code with helper functions commented and with markdown descriptions can be found in the analysis_code.ipynb file. Some of the most relevant conclusions, observations, and selections from the interactive visualizations are presented here.

Takeaways and Observations:
- **LDA for short, specific texts**: LDA does seem to work for shorter texts! While playing around with the coherence scores and number of topics was needed to get interpretable topics, there were surprisingly insightful topics, and looking at their high frequency terms was useful to get a general idea of the contents of the dataset without looking at it closely.
- **Coherence for shorter documents**: Coherence did not work conventionally as a metric for this data. It was primarily useful to get the coherence plots for any number of topics from 2 to 15, and finding the topics with the highest coherence was useful, but did not end up being the best number for interpretability in most cases. The point after which there were 'diminishing' returns for a higher number of topics, or the 'elbow' point, was a more useful metric for this. Using the LDA visualizations to get a good number of topics based on actual interpretatability of the high frequency terms in each of the topics was a great technique that used the coherence plots but did not rely on the max coherence. This might have been due to the texts being short (health tweets), the topics already being defined, resulting in generally higher coherence before modeling with LDA, or a tendency to overfit the data with a higher number of topics when the dataset is large (across all the news, not the subsets).
- **Subsetting specific subtopics using keywords**: Looking at the salient and frequent terms within the women's, men's and children's health subsets was interesting. The women's health data was generally more political, with legal and geographical terms appearing more important across specific topics, most likely due to the prevalence of abortion discussions. Meanwhile, the men's data was both smaller and had the highest coherence for only 2 topics, which were quite easy to interpret, and did not include political or children-related terms. The children's health data topics were more spread out and harder to interpret, but 5 topics did model them fairly well given the small size of the sample. The gendered split across frequent and salient terms with this data was interesting, with 'women' and 'mother' appearing important in certain topics, but not 'men' and 'father'. 

<img width="2676" height="1510" alt="image" src="https://github.com/user-attachments/assets/b000aa46-b422-412c-ba51-2538ada24d00" />

Dataset collected from:
Karami, A. (2017). Health News in Twitter [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C5BW2Q.
